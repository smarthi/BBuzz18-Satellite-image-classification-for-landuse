<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Large Scale Landuse Classification of Satellite Imagery</title>

    <meta name="description" content="Building streaming pipelines for neural machine translation">
    <meta name="author" content="Kellen Sunderland; Suneel Marthi">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="font-awesome-4.7.0/css/font-awesome.min.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/bbuzz17.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
    <!--[if lt IE 9]> <script src="lib/js/html5shiv.js"></script> <![endif]-->
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-background-image="img/brandenburgerTor.jpg">
          <br/>
          <br/>
          <br/>
          <h3>Large Scale Landuse Classification of Satellite Imagery</h3>
          <br/>
          <p>Suneel Marthi
          </p>
          <p style="font-size: 60%">June 11, 2018<br/>
             Berlin Buzzwords, Berlin, Germany</p>
        </section>
				<section data-background-image="img/ZsMwlm2.jpg">
          <h3>$WhoAmI</h3>
          <h6 style='text-align: left; font-size: 80%;'>Suneel Marthi <br/><span style="font-size: 60%"><i class="fa fa-twitter" aria-hidden="true"></i> @suneelmarthi</span></h6>
          <ul style='font-size: 70%;'>
            <li>Member of Apache Software Foundation</li>
            <li>Committer and PMC on Apache Mahout, Apache OpenNLP, Apache Streams</li>
          </ul>
        </section>
        <section data-background-image="img/ZsMwlm2.jpg">
          <h3>Agenda</h3>
          <ul>
            <li>Introduction</li>
            <li>Data description</li>
            <li>Cloud classification</li>
            <li>Segmentation</li>
          </ul>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
          <h4>Goal: Identify Tulip fields from Sentinel-2 satellite images</h4>
            <div style="background: #c9c9c9;">
                <img src='img/tulip-fields.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            </div>
        </section>

        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>Workflow</h4>
            <div style="background: #c9c9c9;">
                <img src='img/slide3.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h3>Data: Sentinel-2</h3>
            <p style='text-align: left'>Earth observation mission from ESA</p>
            <p style='text-align: left'>13 spectral bands, from RGB to SWIR (Short Wave Infrared)</p>
            <p style='text-align: left'>Spatial resolution: 10m/px (RGB bands)</p>
            <p style='text-align: left'>5 day revisit time</p>
            <p style='text-align: left'>Free and open data policy</p>
            <img src='img/slide5.png' style=' position: absolute; right: 0px; bottom: 0px; width: 30%; height: 30%; margin: 0px, 0px, 0px, 0px; border: none; background: none;box-shadow: none; '/><br/>
        </section>

        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <h3>Data acquisition</h3>
            <p style='text-align: left'>Images downloaded using Sentinel Hub’s WMS (web mapping service)</p>
            <p style='text-align: left'>Download tool from Matthieu Guillaumin (@mguillau)</p>
            <table>
                <td><img src='img/slide6.png' style='margin: 0px, 0px, 0px, 0px; border: none; background: none;box-shadow: none; '/><br/></td>
                <td><img src='img/slide6-2.png' style='margin: 0px, 0px, 0px, 0px; border: none; background: none;box-shadow: none; '/><br/></td>
            </table>
        </section>
        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <h3>Data</h3>
            <p style='text-align: left'>256 x 256 px images, RGB</p>
            <img src='img/slide7.png' style='margin: 0px, 0px, 0px, 0px; border: none; background: none;box-shadow: none; '/><br/>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>Workflow</h4>
            <div style="background: #c9c9c9;">
                <img src='img/slide8.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>Cloud filtering</h4>
            <p style='text-align: left'>Need to remove cloudy images before segmenting</p>
            <p style='text-align: left'>Approach: train a Neural Network to classify images as clear or cloudy</p>
            <p style='text-align: left'>Tested CNNs: ResNet50 and ResNet101</p>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>Cloud filtering: training data</h4>
            <p style='text-align: left'>‘Planet: Understanding the Amazon from Space’ Kaggle competition</p>
            <p style='text-align: left'>40K images labeled as clear, hazy, partly cloudy or cloudy</p>
            <img src='img/slide10.png' style='margin: 0px, 0px, 0px, 0px; border: none; background: none;box-shadow: none; '/><br/>
        </section>
        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <p>Cloud Filtering: Training data(2)</p>
            <table>
                <thead>
                <tr>
                    <th>Origin</th><th>No. of Images</th><th>Cloudy Images</th>
                </tr>
                </thead>
                <tbody>
                <tr>
                    <td>Kaggle Competition</td><td>40000</td><td>30%</td>
                </tr>
                <tr>
                    <td>Sentinel-2(hand labelled)</td><td>5000</td><td>50%</td>
                </tr>
                <tr>
                    <td>Total</td><td>45000</td><td>32%</td>
                </tr>
                </tbody>
            </table>
            <p>Only two classes: clear and cloudy (cloudy = haze + partly cloudy + cloudy) </p>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>Training data split</h4>
            <div style="background: #c9c9c9;">
                <img src='img/slide12.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            </div>
        </section>

        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <p>Results</p>
            <table>
                <thead>
                <tr>
                    <th>Model</th><th>Accuracy</th><th>F1</th><th>Epochs (train + finetune)</th>
                </tr>
                </thead>
                <tbody>
                <tr>
                    <td>ResNet50</td><td>0.983</td><td>0.986</td><td>23 + 7</td>
                </tr>
                <tr>
                    <td>ResNet101</td><td>0.978</td><td>0.982</td><td>43 + 9</td>
                </tr>
                </tbody>
            </table>
            <p>Choose ResNet50 for filtering cloudy images</p>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>Example Results</h4>
            <div style="background: #c9c9c9;">
                <img src='img/slide14.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-yellowish.jpg">
            <h3>Data Augmentation
            </h3>

            <img src='img/slide-aug.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>

            <pre><code data-trim data-noescape>
                import Augmentor

                p = Augmentor.Pipeline(img_dir)

                p.skew(probability=0.5, magnitude=0.5)
                p.shear(probability=0.3, max_shear=15)
                p.flip_left_right(probability=0.5)
                p.flip_top_bottom(probability=0.5)
                p.rotate_random_90(probability=0.75)
                p.rotate(probability=0.75, max_rotation=20)
            </code></pre>

            </table>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
            <h4>Example Data Augmentation</h4>
            <div style="background: #c9c9c9;">
                <img src='img/DataAugmentation.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>Workflow</h4>
            <div style="background: #c9c9c9;">
                <img src='img/slide15.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>Segmentation Goals</h4>
            <div style="background: #c9c9c9;">
                <img src='img/slide16.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-yellowish.jpg">
            <h3>Approach U-Net</h3>
            <ul>
                <li>State of the Art CNN for Image Segmentation</li>
                <li>Commonly used with biomedical images</code></li>
                <li>Best Architecture for tasks like this</li>
            </ul>
            <p style="font-size: 35%;"><i>O. Ronneberger, P.Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation. arxiv:1505.04597, 2015</i></p>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>U-Net Architecture</h4>
            <div style="background: #c9c9c9;">
                <img src='img/slide18.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-yellowish.jpg">
            <h3>U-Net Building Blocks</h3>
            <pre><code data-trim data-noescape>
                def conv_block(channels, kernel_size):
                   out = nn.HybridSequential()
                   out.add(
                       nn.Conv2D(channels, kernel_size, padding=1, use_bias=False),
                       nn.BatchNorm(),
                       nn.Activation('relu')
                   )
                   return out
            </code></pre>
            <pre><code data-trim data-noescape>
                def down_block(channels):
                   out = nn.HybridSequential()
                   out.add(
                       conv_block(channels, 3),
                       conv_block(channels, 3)
                   )
                   return out
            </code></pre>
        </section>
        <section data-background-image="img/ZsMwlm2-yellowish.jpg">
            <h3>U-Net Building Blocks (2)</h3>
            <pre><code data-trim data-noescape>
                class up_block(nn.HybridBlock):
                   def __init__(self, channels, shrink=True, **kwargs):
                       super(up_block, self).__init__(**kwargs)
                       self.upsampler = nn.Conv2DTranspose(channels=channels, kernel_size=4,
                                                            strides=2, padding=1, use_bias=False)
                       self.conv1 = conv_block(channels, 1)
                       self.conv3_0 = conv_block(channels, 3)
                       if shrink:
                           self.conv3_1 = conv_block(int(channels/2), 3)
                       else:
                           self.conv3_1 = conv_block(channels, 3)
                   def hybrid_forward(self, F, x, s):
                       x = self.upsampler(x)
                       x = self.conv1(x)
                       x = F.relu(x)
                       x = F.Crop(*[x,s], center_crop=True)
                       x = s + x
                       x = self.conv3_0(x)
                       x = self.conv3_1(x)
                       return x
            </code></pre>
        </section>
        <section data-background-image="img/ZsMwlm2-yellowish.jpg">
            <h3>U-Net: Training data</h3>
            <table>
                <tbody>
                    <tr>
                        <td>
                            <ul>
                                <li>Ground truth: tulip fields in the Netherlands</li>
                                <li>Provided by Geopedia, from Sinergise</li>
                                <img src='img/slide21.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
                            </ul>
                        </td>
                        <td>
                            <img src='img/slide21-2.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
                        </td>

                    </tr>
                </tbody>
            </table>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h4>Loss function: Soft Dice Coefficient loss</h4>
            <img src='img/slide22.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            <p style='...'>Prediction = Probability of each pixel belonging to a Tulip Field (Softmax output)</p>
            <p style='...'>ε serves to prevent division by zero</p>
        </section>
        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <h4>Evaluation Metric: IoU</h4>
            <img src='img/slide23.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
            <p style='...'><i>Aka</i> Jaccard Index</p>
            <p style='...'>Similar to Dice coefficient, standard metric for image segmentation </p>
        </section>
        <section data-background-image="img/ZsMwlm2-yellowish.jpg">
            <h3>Results</h3>
            <ul>
                <li><b>IoU = 0.73</b> after 23 training epochs</li>
                <li>Related results: DSTL Kaggle competition</li>
                <li>IoU = 0.84 on crop vs building/road/water/etc segmentation</li>
            </ul>
            <p style="font-size: 35%;"><i>https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection/discussion/29790</i></p>
        </section>
        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <h3>Was ist Apache Beam?</h3>
            <ul>
                <li>Agnostic (unified Batch + Stream) programming model </li>
                <li>Java, Python, Go SDKs</li>
                <li>Runners for Dataflow</li>
                <ul>
                    <li>Apache Flink</li>
                    <li>Apache Spark</li>
                    <li>Google Cloud Dataflow</li>
                    <li>Local DataRunner</li>
                </ul>
            </ul>
            <img src='img/beam_logo_navbar.png' style=' position: absolute; right: 0px; bottom: 0px; width: 30%; height: 30%; margin: 0px, 0px, 0px, 0px; border: none; background: none;box-shadow: none; '/><br/>
        </section>
        <section data-background-image="img/ZsMwlm2-yellowish.jpg">
            <h3>Warum Apache Beam?</h3>
            <ul>
                <li>Portierbar: Code abstraction that can be executed on different backend runners</li><br>
                <li>Vereinheitlicht: Unified batch and Streaming API</li><br>
                <li>Erweiterbare Modelle und SDK: Extensible API to define custom sinks and sources</li><br>
            </ul>
        </section>

        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <h3>NMT Inference Pipeline</h3>
            <img src='img/pipeline.png' style='max-width: 80%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/buzzwords_2017-blueish.png">
          <h3>Credits</h3>
          <ul>
            <li>Jose Contreras, Matthieu Guillaumin, Kellen Sunderland (Amazon - Berlin)</li>
            <li>Ali Abbas (HERE - Frankfurt)</li>
            <li>Apache Beam: Pablo Estrada, Lukasz Cwik, Sergei Sokolenko (Google)</li>
            <li>Pascal Hahn, Jed Sundvall (Amazon - Germany)</li>
            <li>Apache OpenNLP: Bruno Kinoshita, Joern Kottmann</li>
          </ul>
        </section>
        <section data-background-image="img/ZsMwlm2.jpg">
          <h2>Links</h2>
          <ul>
            <li>Earth on AWS: https://aws.amazon.com/earth/</li>
            <li>Semantic Segmentation - U-Net: https://medium.com/@keremturgutlu/semantic-segmentation-u-net-part-1-d8d6f6005066</li>
            <li>ResNet: https://arxiv.org/pdf/1512.03385.pdf</li>
            <li>U-Net: https://arxiv.org/pdf/1505.04597.pdf</li>
          </ul>
        </section>
        <section>
            <h2>Links (contd)</h2>
            <ul>
                <li>Apache Beam: https://beam.apache.org</li>
                <li>Slides: https://smarthi.github.io/BBuzz18-Satellite-image-classification-for-landuse</li>
                <li>Code: https://github.com/smarthi/satellite-images</li>
            </ul>
        </section>
        <section data-background-image="img/ZsMwlm2.jpg">
          <h2>Fragen ???</h2>
        </section>

			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
        controls: false,
        progress: true,
        history: true,
        center: true,
        slideNumber: true,
        transition: 'slide', // none/fade/slide/convex/concave/zoom
        keyboard: true,
        touch: true,
        loop: false,
        fragments: true,
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
